{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comparative-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "billion-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "maritime-warner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (8, 2, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rental-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ordinary-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extreme-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "killing-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "positive-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "superior-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list()\n",
    "for line in text.split('\\n'): # Wn을 기준으로 문장 토큰화\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "elegant-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(i) for i in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "practical-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "numerical-minutes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "found-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "empty-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "attempted-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes= vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sonic-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "continuing-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_len - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "annual-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') # 데이터에 대한 패딩\n",
    "        result = model.predict_classes(encoded, verbose=0)\n",
    "    # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
    "        for word, index in t.word_index.items(): \n",
    "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "                break # 해당 단어가 예측 단어이므로 break\n",
    "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
    "    # for문이므로 이 행동을 다시 반복\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "limited-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\workspace\\mofiwo\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '경마장에', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "conditional-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_sequences(['경마장에'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "endangered-nevada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 2]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([[2]], maxlen=5, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "strong-translation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('말이', 1),\n",
       " ('경마장에', 2),\n",
       " ('있는', 3),\n",
       " ('뛰고', 4),\n",
       " ('있다', 5),\n",
       " ('그의', 6),\n",
       " ('법이다', 7),\n",
       " ('가는', 8),\n",
       " ('고와야', 9),\n",
       " ('오는', 10),\n",
       " ('곱다', 11)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word, index) for word, index in t.word_index.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "short-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "possible-genesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount            byline documentType  \\\n",
       "0  5adf6684068401528a2aa69b               781    By JOHN BRANCH      article   \n",
       "1  5adf653f068401528a2aa697               656  By LISA FRIEDMAN      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "\n",
       "                                            keywords  multimedia  newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68   Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68  Climate   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'E:/Users/byeungchun/Downloads/ArticlesApril2018.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "optical-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = list(df[~df.headline.apply(lambda x: x == 'Unknown')].headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "premium-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repreprocessing(s):\n",
    "    s=s.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return ''.join(c for c in s if c not in punctuation).lower() # 구두점 제거와 동시에 소문자화\n",
    "\n",
    "text = [repreprocessing(x) for x in headline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "indoor-boundary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'former nfl cheerleaders settlement offer 1 and a meeting with goodell'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "defined-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 3494\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print('단어 집합의 크기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "taken-lloyd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for line in text: # 1,214 개의 샘플에 대해서 샘플을 1개씩 가져온다.\n",
    "    encoded = t.texts_to_sequences([line])[0] # 각 샘플에 대한 정수 인코딩\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "sequences[:11] # 11개의 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "brief-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=24, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "hispanic-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "legendary-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "celtic-hybrid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6988"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-ethernet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
